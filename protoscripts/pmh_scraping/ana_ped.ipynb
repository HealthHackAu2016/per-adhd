{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = np.loadtxt(\"posinfo2.csv\", delimiter=\",\",usecols=(2,6,7,8));\n",
    "text = np.loadtxt(\"posinfo2.csv\", dtype=np.unicode, delimiter=\",\",usecols=(9,));\n",
    "text = np.asarray([t[4:-2] for t in text]) #Hack: np is not parsing text cols right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def def_column(row):\n",
    "    h, tx, ty, p = row\n",
    "    if tx<130:\n",
    "        return \"address\"\n",
    "    elif tx<250:\n",
    "        return \"names\"\n",
    "    elif tx<480:\n",
    "        return \"contact\"\n",
    "    else:\n",
    "        return \"service\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isheader(row):\n",
    "    h, tx, ty, p = row\n",
    "    return h>15\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_pages = np.unique(pos[(np.apply_along_axis(isheader, 1, pos)), 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['address', 'contact', 'service', ..., 'service', 'service',\n",
       "       'service'], \n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = np.apply_along_axis(def_column, 1, pos)\n",
    "#list(map(print,cols))\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isValidRow(row, header_pages):\n",
    "    h,tx,ty,p = row\n",
    "    if ty<30: \n",
    "        return False\n",
    "    elif p in header_pages and ty>500:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "99\n",
      "99\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:1: DeprecationWarning: using a boolean instead of an integer will result in an error in the future\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:2: DeprecationWarning: using a boolean instead of an integer will result in an error in the future\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:3: DeprecationWarning: using a boolean instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:4: DeprecationWarning: using a boolean instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "print(len(text[cols == 1] ))\n",
    "print(len(text[cols == 2] ))\n",
    "print(len(text[cols == 3] ))\n",
    "print(len(text[cols == 4] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rows(pos, text):\n",
    "    header_pages = np.unique(pos[(np.apply_along_axis(isheader, 1, pos)), 3])\n",
    "    valid_rows =  np.asarray([isValidRow(row, header_pages) for row in pos])\n",
    "    \n",
    "    vpos = pos[valid_rows,:]\n",
    "    vtext = text[valid_rows]\n",
    "    entries = defaultdict(lambda : {'address': '', 'names': '', 'contact': '', 'service':''} )\n",
    "    for page in np.unique(vpos[:,-1]):\n",
    "        print(page)\n",
    "        page_row_inds = vpos[:,-1]==page\n",
    "        page_pos = vpos[page_row_inds, :]\n",
    "        page_text = vtext[page_row_inds]\n",
    "\n",
    "        cell_bottom_inds = np.logical_or(page_text == \"Fax\", page_text == \"Fax:\")\n",
    "        cell_bottoms_ty = page_pos[cell_bottom_inds, -2]\n",
    "        cell_bottoms_ty.sort()\n",
    "        \n",
    "        \n",
    "        \n",
    "        row_assignments = []\n",
    "        for (ii,((h,tx,ty,p), tt)) in enumerate(zip(page_pos, page_text)):\n",
    "            for (row_ii, bottom_ty) in enumerate(cell_bottoms_ty[::-1]):\n",
    "                if ty>= bottom_ty:\n",
    "                    row_assignments.append(row_ii)\n",
    "                    #print(\"good \", tt, \" at \", row_ii)\n",
    "                    break \n",
    "            else:\n",
    "                pass\n",
    "                #print(\"warn: \", tt)\n",
    "                #row_assignments.append(length(cell_bottoms_ty))\n",
    "                \n",
    "        col_assignments = np.apply_along_axis(def_column, 1, page_pos)\n",
    "        \n",
    "        \n",
    "        for (tt, col_ass, row_ass) in zip(page_text, col_assignments, row_assignments):\n",
    "            entries[(page, row_ass)][col_ass]+=tt\n",
    "            \n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "entries = get_rows(pos,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def varients(alt_name):\n",
    "    yield alt_name\n",
    "    yield alt_name.lower()\n",
    "    yield \"\".join(alt_name.split())\n",
    "    yield \"\".join(alt_name.lower().split())\n",
    "    yield re.sub(r'[^\\w]', '', alt_name)\n",
    "    yield re.sub(r'[^\\w]', '', alt_name.lower())\n",
    "    #Maybe we miss things with spaces and symbols?\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_service_aliases():\n",
    "    servise_names = json.load(open(\"./spec_types.json\",\"r\"))\n",
    "    aliases = {}\n",
    "    for canon_name, altnames in  servise_names.items():\n",
    "        \n",
    "        for altname in altnames:\n",
    "            for varient in varients(altname):\n",
    "                if len(varient) == 1:\n",
    "                    continue\n",
    "                    \n",
    "                aliases[varient] = canon_name\n",
    "        for varient in canon_name:\n",
    "            if len(varient) == 1:\n",
    "                continue\n",
    "\n",
    "            aliases[varient] = canon_name\n",
    "    return aliases\n",
    "        \n",
    "\n",
    "    \n",
    "    SERVICE_ALIASES = load_service_aliases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def NameCase(s):\n",
    "    return s[0].upper() + s[1:].lower() \n",
    "\n",
    "\n",
    "def parse_address(tt):\n",
    "    loc_parts = re.findall(r\"[A-Z][A-Z]+\", tt)\n",
    "    if loc_parts==['WA']:\n",
    "        #Only WA found\n",
    "        loc_parts = re.findall(r\"[A-Z|a-z]+(?=\\sWA)\", tt)\n",
    "    \n",
    "     \n",
    "    loc_parts=filter(lambda p: p!=\"WA\", loc_parts)\n",
    "    loc_parts = map(NameCase, loc_parts)\n",
    "\n",
    "    \n",
    "    return \"area\", \" \".join(loc_parts)\n",
    "\n",
    "\n",
    "def parse_names(tt):\n",
    "#    uc = [t==t.upper]\n",
    "\n",
    "    \n",
    "    names =[]\n",
    "    \n",
    "    namey_bits =  re.findall(r\"[A-Z][A-Z]+[a-z]+\", tt)\n",
    "    if len(namey_bits)>0:\n",
    "        for namey_bit in namey_bits:\n",
    "            fistname_start = re.search(\"[a-z]\", namey_bit).start() - 1\n",
    "            last_name = NameCase(namey_bit[:fistname_start-1])\n",
    "            first_name = NameCase(namey_bit[fistname_start:])\n",
    "            \n",
    "            names.append(first_name+\" \"+last_name)\n",
    "    else:\n",
    "        names = map(NameCase,re.findall(r\"[A-Z][A-Z]+\", tt))\n",
    "        \n",
    "    names = [\"Dr \" + name for name in names]\n",
    "    return  \"name\",\" \".join( names)\n",
    "\n",
    "\n",
    "\n",
    "def parse_services(tt):\n",
    "    mad_skills = set()\n",
    "    for skill_varname, canon_name in SERVICE_ALIASES.items():\n",
    "        if skill_varname in tt:\n",
    "            mad_skills.add(canon_name)\n",
    "    return  \"expertise\", list(mad_skills)\n",
    "\n",
    "\n",
    "def parse_contact(tt):\n",
    "    numbers = re.findall(r\"[0-9][0-9][0-9][0-9] [0-9][0-9][0-9][0-9]\", tt)\n",
    "    if len(numbers) == 0: \n",
    "        return  \"number\",\"\"        \n",
    "    else:\n",
    "        return \"number\", numbers[-1]\n",
    "\n",
    "\n",
    "parsers = {'address': parse_address, 'names': parse_names, 'contact': parse_contact, 'service': parse_services}\n",
    "\n",
    "def make_data_for_jvb(entry):\n",
    "    jvb_format = {'specialistType': \"Paediatrican\"}\n",
    "    \n",
    "    for key, tt in entry.items():\n",
    "        jvb_key, jvb_value = parsers[key](tt)\n",
    "        jvb_format[jvb_key] = jvb_value\n",
    "        \n",
    "    return jvb_format\n",
    "    \n",
    "    \n",
    "def make_all_data_for_jon(entries):\n",
    "    data=[]\n",
    "    for entry in entries.values():\n",
    "        datum = make_data_for_jvb(entry)\n",
    "        if len(datum['name'].strip()) > 0: \n",
    "            data.append(datum)\n",
    "    return data\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': 'Joondalup',\n",
       " 'expertise': ['Autism Spectrum Disorder', 'Adolescents'],\n",
       " 'name': 'Dr Jongelin',\n",
       " 'number': '9400 9910',\n",
       " 'specialistType': 'Paediatrican'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_data_for_jvb(list(entries.values())[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../../www/default-data/auto_ped.json\",\"w\") as fh:\n",
    "    json.dump(make_all_data_for_jon(entries), fh, sort_keys=True, indent=4, separators=(',', ': '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_ped.json  auto_psych.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../www/default-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
